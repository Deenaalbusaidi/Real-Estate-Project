{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a12b0a0-ed30-4e66-a483-2c9d27596765",
   "metadata": {},
   "source": [
    "# **Bayut Oman Rentals**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbbdd99-ecd2-4fba-bd2b-90c7e2cbdddf",
   "metadata": {},
   "source": [
    "### **Installing Selenium Library**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009d19c7-7a11-46d3-ad68-e388e311be73",
   "metadata": {},
   "source": [
    "### **Setting The Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "433a2dca-5c8b-4077-97dd-3b230ee09be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb32f726-2df1-4142-8002-12736537afec",
   "metadata": {},
   "source": [
    "### **Opening the Bayut rental page using Chrome**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "be9dd783-c2e2-4577-9247-716160d17dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Error scraping page 1: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Error fetching detail from https://www.bayut.om/en/property/details-130250150.html: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Error fetching detail from https://www.bayut.om/en/property/details-129421978.html: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Scraping page 8...\n",
      "Error scraping page 8: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Scraping page 9...\n",
      "Error scraping page 9: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Scraping page 16...\n",
      "Scraping page 17...\n",
      "Scraping page 18...\n",
      "Scraping page 19...\n",
      "Scraping page 20...\n",
      "Scraping page 21...\n",
      "Scraping page 22...\n",
      "Scraping page 23...\n",
      "Scraping page 24...\n",
      "Scraping page 25...\n",
      "Scraping page 26...\n",
      "Scraping page 27...\n",
      "Error fetching detail from https://www.bayut.om/en/property/details-129945405.html: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Error fetching detail from https://www.bayut.om/en/property/details-130198304.html: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Error fetching detail from https://www.bayut.om/en/property/details-129950997.html: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Error fetching detail from https://www.bayut.om/en/property/details-129416377.html: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Scraping page 28...\n",
      "Scraping page 29...\n",
      "Scraping page 30...\n",
      "Scraping page 31...\n",
      "Scraping page 32...\n",
      "Scraping page 33...\n",
      "Scraping page 34...\n",
      "Scraping page 35...\n",
      "Error fetching detail from https://www.bayut.om/en/property/details-129875446.html: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Error fetching detail from https://www.bayut.om/en/property/details-129759791.html: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Error fetching detail from https://www.bayut.om/en/property/details-129636952.html: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Scraping page 36...\n",
      "Scraping page 37...\n",
      "Scraping page 38...\n",
      "Scraping page 39...\n",
      "Scraping page 40...\n",
      "Scraping page 41...\n",
      "Scraping page 42...\n",
      "Scraping page 43...\n",
      "Scraping page 44...\n",
      "Scraping page 45...\n",
      "Scraping page 46...\n",
      "Scraping page 47...\n",
      "Scraping page 48...\n",
      "Scraping page 49...\n",
      "Scraping page 50...\n",
      "Error fetching detail from https://www.bayut.om/en/property/details-130105118.html: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Error fetching detail from https://www.bayut.om/en/property/details-129941716.html: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Error fetching detail from https://www.bayut.om/en/property/details-129061175.html: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Error fetching detail from https://www.bayut.om/en/property/details-129148541.html: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Error fetching detail from https://www.bayut.om/en/property/details-129792845.html: HTTPSConnectionPool(host='www.bayut.om', port=443): Read timed out. (read timeout=None)\n",
      "Scraping page 51...\n",
      "Scraping page 52...\n",
      "Scraping page 53...\n",
      "Scraping page 54...\n",
      "Scraping page 55...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://www.bayut.om/en/oman/properties-for-rent/page/{}/'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "properties = {\n",
    "    \"Title\": [],\n",
    "    \"Location\": [],\n",
    "    \"Price\": [],\n",
    "    \"Size\": [],\n",
    "    \"Bedrooms\": [],\n",
    "    \"Listing_Type\": [],\n",
    "    \"Link\": []\n",
    "}\n",
    "\n",
    "max_pages = 55\n",
    "\n",
    "for page_num in range(1, max_pages + 1):\n",
    "    url = base_url.format(page_num)\n",
    "    print(f\"Scraping page {page_num}...\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        ads = soup.find_all('article', class_='fbc619bc')\n",
    "\n",
    "        if not ads:\n",
    "            print(\"No more ads found.\")\n",
    "            break\n",
    "\n",
    "        for ad in ads:\n",
    "            # Initialize placeholders\n",
    "            title = None\n",
    "            link = None\n",
    "            location = None\n",
    "            price = None\n",
    "            size = None\n",
    "            bedrooms = None\n",
    "            listing_type = \"For Rent\"\n",
    "\n",
    "            # Title and Link\n",
    "            title_tag = ad.find('a', attrs={'aria-label': 'Listing link'})\n",
    "            if title_tag:\n",
    "                title = title_tag.get('title')\n",
    "                href = title_tag.get('href')\n",
    "                link = 'https://www.bayut.om' + href if href else None\n",
    "\n",
    "            # Location\n",
    "            location_tag = ad.find('div', attrs={'aria-label': 'Location'})\n",
    "            if location_tag:\n",
    "                location = location_tag.text.strip()\n",
    "            elif title:\n",
    "                match = re.search(r'in\\s(.+)', title)\n",
    "                if match:\n",
    "                    location = match.group(1)\n",
    "\n",
    "            # Price\n",
    "            price_tag = ad.find('span', attrs={'aria-label': 'Price'})\n",
    "            if price_tag:\n",
    "                price = price_tag.text.strip()\n",
    "\n",
    "            # Fetch detail page to get Bedrooms and Size\n",
    "            if link:\n",
    "                try:\n",
    "                    detail_response = requests.get(link, headers=headers)\n",
    "                    detail_soup = BeautifulSoup(detail_response.content, 'html.parser')\n",
    "\n",
    "                    # Bedrooms\n",
    "                    bed_container = detail_soup.find('span', attrs={'aria-label': 'Beds'})\n",
    "                    if bed_container:\n",
    "                        bed_text = bed_container.find('span', class_=re.compile(r'_140e6903'))\n",
    "                        if bed_text:\n",
    "                            bedrooms = bed_text.text.strip()\n",
    "\n",
    "                    # Size\n",
    "                    size_container = detail_soup.find('span', attrs={'aria-label': 'Area'})\n",
    "                    if size_container:\n",
    "                        size_text = size_container.find('span', class_=re.compile(r'_140e6903'))\n",
    "                        if size_text:\n",
    "                            size_inner = size_text.find('span')\n",
    "                            if size_inner:\n",
    "                                size = size_inner.text.strip()\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fetching detail from {link}: {e}\")\n",
    "\n",
    "            # Append to dictionary\n",
    "            properties[\"Title\"].append(title)\n",
    "            properties[\"Link\"].append(link)\n",
    "            properties[\"Location\"].append(location)\n",
    "            properties[\"Price\"].append(price)\n",
    "            properties[\"Size\"].append(size)\n",
    "            properties[\"Bedrooms\"].append(bedrooms)\n",
    "            properties[\"Listing_Type\"].append(listing_type)\n",
    "\n",
    "        time.sleep(1)  # Be polite to the server\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping page {page_num}: {e}\")\n",
    "\n",
    "# Final check for length consistency (optional)\n",
    "lengths = {k: len(v) for k, v in properties.items()}\n",
    "if len(set(lengths.values())) > 1:\n",
    "    print(\"Warning: Column lengths are not equal!\")\n",
    "    print(lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2866c1d0-0f92-457c-9cc7-0a322f1e271d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping complete. Saved 1248 listings to 'bayut_properties_for_rent.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "df = pd.DataFrame(properties)\n",
    "df.to_csv(\"bayut_properties_for_rent.csv\", index=False)\n",
    "print(f\"\\nScraping complete. Saved {len(df)} listings to 'bayut_properties_for_rent.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
